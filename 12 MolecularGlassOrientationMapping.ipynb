{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d26383-9387-46d0-991b-5577287ec963",
   "metadata": {},
   "source": [
    "# Orientation mapping for Molecular Glasses\n",
    "\n",
    "This notebook looks into doing orientation mapping for polymers using hyperspy and pyxem.  This is a similar work flow for producing figures similar to those in the paper:\n",
    "```\n",
    "Using 4D STEM to Probe Mesoscale Order in Molecular Glass Films Prepared by Physical Vapor Deposition\n",
    "Debaditya Chatterjee, Shuoyuan Huang, Kaichen Gu, Jianzhu Ju, Junguang Yu, Harald Bock, Lian Yu, M. D. Ediger, and Paul M. Voyles\n",
    "Nano Letters 2023 23 (5), 2009-2015\n",
    "DOI: 10.1021/acs.nanolett.3c00197\n",
    "```\n",
    "\n",
    "In this paper disk like structures in the glass are oriented in domains in the molecular glass.  These domains result from Pi-Pi like stacking and the orientation of the structure can be measured by 4-D STEM. \n",
    "\n",
    "Here we will go through the processing in pyxem/ hyperspy to create a figure similar to the image below which comes from the above paper.\n",
    "\n",
    "<center><img src=\"data/12/ExampleImage.jpeg\" style=\"height:400px\"></center>\n",
    "\n",
    "This is also a good example of how to develop custom workflows in pyxem.  This might eventaully be added as a supported feature to pyxem/hyperspy using the `Model` class upstream in hyperspy but this requires that parallel processing in `hyperspy` when fitting signals is improved.  \n",
    "\n",
    "There are a couple of really cool things to focus on. Specifically this make heavy use of the `map` function in order to make these workflows both parallel and operate out of memory. This notebook is also designed to be easy to modify in the case that you have a different function that you want to fit!\n",
    "\n",
    "The raw data used in section1 can be found at the link below:\n",
    "\n",
    "https://app.globus.org/file-manager?origin_id=82f1b5c6-6e9b-11e5-ba47-22000b92c6ec&origin_path=%2Fmdf_open%2Fchatterjee_phenester_orientation_v1.3%2FFig2%2Fhttps://app.globus.org/file-manager?origin_id=82f1b5c6-6e9b-11e5-ba47-22000b92c6ec&origin_path=%2Fmdf_open%2Fchatterjee_phenester_orientation_v1.3%2FFig2%2F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0ee14-e038-4f86-b282-8c3007a7f7a2",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "0. [Loading the Data/Setup](#Section0)\n",
    "1. [Removing Ellipticity and Polar Unwrapping](#Section1)\n",
    "2. [Processing the Polar Spectrum](#Section2)\n",
    "    1. [Smoothing Functions](#Section2a)\n",
    "3. [Fitting The Polar Spectrum](#Section3)\n",
    "    1. [Fitting Functions](#Section3a)\n",
    "    2. [Testing Initial Parameters](#Section3b)\n",
    "    3. [Visualizing the Results and Checking](#Section3c)\n",
    "4. [Making a Figure with Flow Lines](#Section4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720d03b-50c9-4f54-b32b-4138ee72e198",
   "metadata": {},
   "source": [
    "<a id='Section0'></a>\n",
    "# 0. Loading the Data/ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f231f-db10-45de-8381-a687a28dbe8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hyperspy.api as hs # importing hyperspy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef0bd65-ad3e-42bd-9483-e08b96495f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865ce2a3-1819-41ea-9d51-5ac7f32bc92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "store2 = zarr.ZipStore(path=\"data/12/data_processed.zspy\")\n",
    "s = hs.load(store2, lazy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b6e458-05ef-4e9c-b370-d7479951eb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_dp = s.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de78c2-8d76-457e-a3b3-b2b5ea85ae07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_dp.compute()# Compute the mean Diffraciton pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09bf27a-7d19-40ce-a878-77aca96d0102",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Section1'></a>\n",
    "# 1.0 Removing Ellipticity and Polar Unwrapping\n",
    "\n",
    "Often times you will have some ellipticity in a diffraction pattern or you might not know the exact center. \n",
    "\n",
    "In pyxem we have a method `determine_ellipse` which can be used to find some ellipse.  This is useful for patterns where you don't have a zero beam to find the beam shift.  It is a pretty simple function, it just finds the max points in the diffraction pattern and uses those to define an ellipse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9812d-80db-443d-8681-f3114cd8a296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyxem.utils.ransac_ellipse_tools import determine_ellipse, _get_max_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d519d349-8af0-49c5-82c4-25b0cad5cfd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mean_dp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead31af1-da36-4e48-923b-c0ecbb7a0270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.morphology import disk, dilation\n",
    "mask  = np.logical_not((mean_dp>.001) * (mean_dp<.8))\n",
    "mask.data = dilation(mask.data, disk(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc198d44-e169-4546-b9ce-d240672bf1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7dd41-30fe-41c4-8b24-a3d0544779a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pos = _get_max_positions(mean_dp, mask=mask.data, num_points=900)\n",
    "plt.figure()\n",
    "plt.imshow(mean_dp.data)\n",
    "plt.scatter(pos[:, 1], pos[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d18c03-acbe-411a-bc69-aca61fd13fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "center, affine = determine_ellipse(mean_dp, mask=mask.data, num_points=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3facfcf0-12f2-4a77-bf17-4275024ed9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93925c-7b30-472e-9946-d3c57f9329af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Polar conversion on mean DP using pyXem\n",
    "mean_dp.set_signal_type('electron_diffraction') # \n",
    "mean_dp.unit = \"k_A^-1\" # setting unit\n",
    "mean_dp.beam_energy = 200 # seting beam energy \n",
    "mean_dp.camera_length = 1700\n",
    "mean_dp.set_ai(center=center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0095083-7e5a-41fc-8fc4-e6c5f36be63e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_dp.get_azimuthal_integral2d(npt=100,radial_range=(0.2,0.75), sum=True).plot(vmax=.4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce739fe-e62e-4f83-b0da-bd41267057eb",
   "metadata": {},
   "source": [
    "Now we can use the same parameters on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d75cfd-9d01-40c9-8d15-7e6e35883e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Polar conversion on mean DP using pyXem\n",
    "s.set_signal_type('electron_diffraction') # \n",
    "s.unit = \"k_A^-1\" # setting unit\n",
    "s.beam_energy = 200 # seting beam energy \n",
    "s.camera_length = 1700\n",
    "s.set_ai(center=center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c391ff08-d594-4ee1-946e-07260e26b662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ps = s.get_azimuthal_integral2d(npt=100,radial_range=(0.2,0.75), sum=True) # Use sum=True to conserve counts\n",
    "pss = ps.isig[:,0.25:0.35].sum(axis=-1) #Radial k-summed azimuthal intensity profiles\n",
    "pss.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948a660-3d8e-4d8e-be80-d71a4099eb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pss.save(\"data/PolarSum.zspy\", overwrite=False) # Saving the data for use later (we are going to use some precomputed stuff which is a little larger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5246cfc6-e789-4766-b26d-e5bc4dc4b23c",
   "metadata": {},
   "source": [
    "<a id='Section2'></a>\n",
    "# 2. Processing the Polar Spectrum\n",
    "\n",
    "\n",
    "The radial spectra have a fair bit of noise so we should think about filtering the data.  In this case we can smooth the data before fitting the two arcs.  Using a larger sigma smooths the data more at the cost of losing small features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1bc01f-9d2a-4be2-8894-4af833858e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hyperspy.api as hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ea9cd-9e8c-460b-8847-1e3e867920ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c490a8-b200-4873-adea-1a28cc0b11eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pss = hs.load(\"data/12/PolarSum.zspy\", lazy=True)\n",
    "pss.rechunk((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951d232-e34b-4813-bd2f-438b574edb58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86881446-9d03-4385-9ed0-cbde28d02fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89cf286-705e-443b-b4fd-826281926d7f",
   "metadata": {},
   "source": [
    "<a id='Section2a'></a>\n",
    "## 2a. Smoothing Functions\n",
    "\n",
    "These are just some custom functions for filtering when there is a zero beam.  It just ignores the zero beam when guassian filtering so that \n",
    "intensity doesn't bleed into the masked region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f07bf-b25f-4ac6-bb2f-b1a84a4cedbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Helper Functions (can ignore for the most part)\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import numpy as np\n",
    "from pyxem.utils.signal import to_hyperspy_index\n",
    "    \n",
    "def mask_gaussian1D(data,\n",
    "                    sigma,\n",
    "                    masked_region=None,\n",
    "                   ):\n",
    "    \"\"\"Gaussian smooth the data with a masked region which is ignored.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: array-like\n",
    "        A 1D array to be filtered\n",
    "    sigma: float\n",
    "        The sigma used to filter the data\n",
    "    masked_region: tuple or None\n",
    "        The region of the data to be ignored\n",
    "    \"\"\"\n",
    "    if masked_region is not None:\n",
    "        data_smooth = np.zeros(data.shape)\n",
    "        data_smooth[0:masked_region[0]] = gaussian_filter1d(data[0:masked_region[0]],sigma)\n",
    "        data_smooth[masked_region[1]:] = gaussian_filter1d(data[masked_region[1]:],sigma)\n",
    "    else:\n",
    "        data_smooth = gaussian_filter1d(data,sig)\n",
    "    return data_smooth\n",
    "\n",
    "def smooth_signal(signal, sigma, masked_region=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Helper function to smooth a signal.  The masked_region will use real units if the \n",
    "    values are floats and pixel units if an int is passed\n",
    "    \"\"\"\n",
    "    if masked_region is not None:\n",
    "        masked_region =[to_hyperspy_index(m, signal.axes_manager.signal_axes[0]) for m in masked_region]\n",
    "    return signal.map(mask_gaussian1D, sigma=sigma, masked_region=masked_region, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f28966-fe76-4b15-8f2d-a2ccaef38b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smoothed = smooth_signal(pss,\n",
    "                         sigma=5,\n",
    "                         masked_region=(-0.2, 0.1),\n",
    "                         inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ac8ae-3d36-4739-a9fc-e76afe30d728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smoothed.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882cb689-3e1a-4771-a4b1-69e85d8e7f11",
   "metadata": {},
   "source": [
    "<a id='Section3'></a>\n",
    "# 3. Fitting The Polar Spectrum\n",
    "\n",
    "Now that we have a polar spectrum defined we can start to fit the peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15f5ba-2194-4ded-9fb6-3e86511b1ccb",
   "metadata": {},
   "source": [
    "<a id='Section3a'></a>\n",
    "## 3.a Fitting Functions\n",
    "\n",
    "These functions below help to initalize the fit and then to fit the data using the `map` function.  We could equivilently use the hyperspy.model and `multifit` function but the `multifit` function is a little too slow for the amount of data that we want to process.  We also have a very good idea of the location of the peaks in the data from the \"guess\" and we can use that to our advantage to help speed up the operation.\n",
    "\n",
    "The model is still a good place to play around with parameters and see if things work for the first position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e44f9e-23a3-421c-9853-7a8721490928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional Helper functions for fitting the signal\n",
    "from functools import partial\n",
    "from scipy.optimize import curve_fit\n",
    "# Take initial guess of peak position\n",
    "def guess_peak(data,kernel):\n",
    "    x2 = np.linspace(-np.pi,np.pi,360)\n",
    "    corr = np.correlate(data,kernel,'same')\n",
    "    x = x2[np.argmax(corr)]\n",
    "    # if max peak is second peak then shift 180 degrees\n",
    "    if x > np.pi:\n",
    "        x = x-np.pi\n",
    "    elif x<0:\n",
    "        x =x+np.pi\n",
    "    return x \n",
    "# Gaussian function\n",
    "def gaussian(x,a,p,sig):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: array-like\n",
    "        The positions at which to ca\n",
    "    a:\n",
    "        Height of the Gaussian\n",
    "    p:\n",
    "        The Position of the center of the peak\n",
    "    sigma:\n",
    "        The sigma value for the gaussian\n",
    "    \"\"\"\n",
    "    return a*np.exp(-(x-p)**2/(2*sig**2))\n",
    "\n",
    "# Fitting function (single pair)\n",
    "def composite(x, # phi\n",
    "              y_offset,# baseline\n",
    "              peak1_pos,a_peak1, a_peak2, sig,# peak intensities, position and sigma\n",
    "              beam_stop_pos): # beamstop\n",
    "    beamstop = np.ones(len(x))\n",
    "    beamstop[beam_stop_pos[0]:beam_stop_pos[1]]=0\n",
    "    return (y_offset + \n",
    "            gaussian(x, a_peak1, peak1_pos, sig) +\n",
    "            gaussian(x, a_peak2, peak1_pos-np.pi, sig)+ \n",
    "            gaussian(x, a_peak1, peak1_pos+np.pi, sig))*beamstop\n",
    "\n",
    "# Fit peak parameters\n",
    "def peak_fit(data,\n",
    "             composite, \n",
    "             fixed_parameters,\n",
    "             bounds,\n",
    "             fitting_kwds = [\"y_offset\", \"peak1_pos\", \"a_peak1\", \"a_peak2\", \"sig\"],\n",
    "             method='chi2',\n",
    "             **kwargs):\n",
    "    \"\"\"\n",
    "    A general function to fit the composite function defined above.\n",
    "    \n",
    "    This function can be generalized to any composite function by creating a new function.\n",
    "    \n",
    "    The fixed parameters are fixed during the fitting while other kwargs passed only represent the initial parameters for fitting\n",
    "    and are iteratively changed to minimize the cost function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        The data to be fit. A 1-D array\n",
    "    composite: func\n",
    "        The funtion to be fit\n",
    "    fixed_parameters: dict\n",
    "        A dictionary mapping between the fixed parameters for the function that is being optimized. \n",
    "    bounds: \n",
    "        The bounds for the parameters which are being fit in a dictionary\n",
    "        i.e.: bounds = {\"y_offset\":(low_y, hi_y), \"peak1_pos\":(low_pos, hi_pos),}\n",
    "    fitting_kwds: list\n",
    "        The list of keywords that are passed to the function to be fit.\n",
    "    method:\n",
    "        The statistical analysis of the fit to return\n",
    "    kwargs:\n",
    "        The inital values for the composite function as well as any keyword arguments for `scipy.optimize.curve_fit`\n",
    "    \"\"\"\n",
    "    data = data+0.00000000001 # handle zeros\n",
    "    \n",
    "    comp = partial(composite, **fixed_parameters) # set fixed values\n",
    "    x2 = np.linspace(-np.pi,np.pi,360)\n",
    "    initial_guess = [kwargs.pop(k, 1) for k in fitting_kwds]\n",
    "    unpacked_bounds = (tuple([bounds.get(k, (-np.inf, np.inf))[0] for k in fitting_kwds]),\n",
    "                       tuple([bounds.get(k, (-np.inf, np.inf))[1] for k in fitting_kwds]))\n",
    "    try:\n",
    "        popt,pcov = curve_fit(comp,\n",
    "                              x2,\n",
    "                              data,\n",
    "                              p0=initial_guess,\n",
    "                              bounds=unpacked_bounds,\n",
    "                              sigma=1/np.power(data,1/4),\n",
    "                              method='trf',\n",
    "                              **kwargs)\n",
    "    except:\n",
    "        return [1,0,0,0,0,0]\n",
    "\n",
    "    if method == 'std':\n",
    "        gof = np.sum(np.sqrt(np.diag(pcov)))\n",
    "    if method == 'chi2':\n",
    "        gof = np.nansum(((comp(x2, *popt)-data)**2/data)[data>0])/(360-len(unpacked_bounds[0]))\n",
    "    if method == 'r2':\n",
    "        ss_tot = np.sum((data-np.mean(data))**2)\n",
    "        ss_res = np.sum((data-comp(x2, *popt))**2)\n",
    "        gof = 1-ss_res/ss_tot\n",
    "    return np.array([gof,*popt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44babea-4235-4bca-a629-22979316eaba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x2 = np.linspace(-np.pi,np.pi,360)\n",
    "kernel = gaussian(x2,35,0,0.36)+8\n",
    "orientation_guess = smoothed.map(guess_peak,\n",
    "                         kernel=kernel,\n",
    "                         inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91189b56-3464-4261-8bba-5f7011091839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orientation_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a9796a-91dd-4b7f-9346-21a9c63c51d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orientation_guess.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2409ab-fc36-4f81-a01c-7892958977ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orientation_guess.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6265fe-e4da-4c9f-a7a9-aa8964335ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inital Parameters for fitting\n",
    "bounds = {\"y_offset\": (0,2),\n",
    "          \"peak1_pos\": (0, np.pi),\n",
    "          \"a_peak1\":(2, 15),\n",
    "          \"a_peak2\":(2,15),\n",
    "          \"sig\": (0.1, 0.3)\n",
    "         }\n",
    "\n",
    "inital_pos = {\"y_offset\": 1,\n",
    "              \"a_peak1\":4,\n",
    "              \"a_peak2\":4,\n",
    "              \"sig\":.2,}\n",
    "beam_stop_pos = [to_hyperspy_index(edge, smoothed.axes_manager.signal_axes[0]) for edge in (-0.2, 0.1)]\n",
    "\n",
    "fixed_parameters = {\"beam_stop_pos\":beam_stop_pos}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002649ac-97ac-4a40-bafe-0288ae4e60a4",
   "metadata": {},
   "source": [
    "<a id='Section3b'></a>\n",
    "\n",
    "## 3.b Testing Inital Parameters:\n",
    "\n",
    "Let's look at one position in the dataset and see if our inital parameters and bounds are reasonable. You have to adjust these values a little bit \n",
    "to make things a little easier to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26370173-b42e-4788-b682-a7c47ec5ee8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = smoothed.inav[4,4].data.compute()\n",
    "orientation = orientation_guess.inav[4,4].data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46814ea-aa78-46c8-ae99-1e544f4fdcc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peaks = smoothed.map(peak_fit,\n",
    "                     composite=composite,\n",
    "                     fixed_parameters=fixed_parameters,\n",
    "                     bounds=bounds,\n",
    "                     peak1_pos=orientation_guess,\n",
    "                     inplace=False,\n",
    "                     **inital_pos,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611cf7f-1ba9-4138-a3b7-3237addfe93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "x = np.linspace(-np.pi,np.pi,360)\n",
    "plt.plot(x, data, label=\"Original Data\")\n",
    "\n",
    "initial_fit = composite(x,\n",
    "                        beam_stop_pos=beam_stop_pos,\n",
    "                        peak1_pos=orientation,\n",
    "                        **inital_pos,\n",
    "                       )\n",
    "plt.plot(x,\n",
    "         initial_fit,\n",
    "         label=\"Initial Fit\")\n",
    "\n",
    "fitted = peak_fit(data,\n",
    "                  composite=composite,\n",
    "                  fixed_parameters=fixed_parameters,\n",
    "                  bounds=bounds,\n",
    "                  peak1_pos=orientation,\n",
    "                  **inital_pos,)\n",
    "plt.plot(x,composite(x,\n",
    "                     *fitted[1:],\n",
    "                     beam_stop_pos=beam_stop_pos,\n",
    "                    ),\n",
    "         label=\"fitted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54fb57c-cdc3-42b0-b242-4a8a7cf72ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "beam_stop_pos = [to_hyperspy_index(edge, smoothed.axes_manager.signal_axes[0]) for edge in (-0.2, 0.1)]\n",
    "peaks = smoothed.map(peak_fit,\n",
    "                     composite=composite,\n",
    "                     fixed_parameters=fixed_parameters,\n",
    "                     bounds=bounds,\n",
    "                     peak1_pos=orientation_guess,\n",
    "                     inplace=False,\n",
    "                     **inital_pos,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e37f7-d5cd-4abd-a1a2-4ca0d421162c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peaks.data[3,4].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c01cc-c4af-498a-8e68-2deafafd0b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run fitting in parallel (Should take a minute or two)\n",
    "peaks.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51176c-efaa-494a-8b09-380aae622f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hs.plot.plot_images(peaks.T,\n",
    "                    label=[\"Chi^2\",\"Backgrond\", \"Orientation\", \"Peak1 Amplitude\", \"Peak2 Amplitude\", \"Sigma\"],\n",
    "                per_row=3, tight_layout=True, scalebar=\"all\", axes_decor=\"off\",scalebar_color=\"white\", cmap=\"hot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97b2e0-89e0-4d63-a4f4-9ca064c069db",
   "metadata": {},
   "source": [
    "<a id='Section3c'></a>\n",
    "## 3.c Visualizing the Results and Checking for Accuracy\n",
    "\n",
    "We can always see how well our fit performed but plotting both signals on top of each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab85cc-d134-42ce-bdc2-44fe5de16387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a cyclical mcap from 0-> pi\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "cdata = np.loadtxt('data/12/colorwheel.txt')\n",
    "cmap= LinearSegmentedColormap.from_list('my_colormap', cdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565c8a5-6dab-4df8-84c2-89ffe925ae84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_composite(data):\n",
    "    x = np.linspace(-np.pi,np.pi,360)\n",
    "    return composite(x,*data[1:], beam_stop_pos=beam_stop_pos,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc0b39-44ce-4ff1-b75c-75019441bc7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ans = peaks.map(apply_composite, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a8785-92b8-430a-97e1-da5cb367b464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just add in the answer as a complex signal.\n",
    "both = smoothed+ans.data*1j\n",
    "both.metadata.General.title= \"Fit+Smoothed Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1e9d5-7a5f-468d-90d1-58bb30a814c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "both.navigator = peaks.isig[2]\n",
    "both.axes_manager.navigation_axes[0].index=12\n",
    "both.axes_manager.navigation_axes[1].index=15\n",
    "both.plot(navigator_kwds={\"cmap\":cmap,\n",
    "                          \"interpolation\":'none'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd548a78-5525-48a5-b85e-3181fa2bd021",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Section4'></a>\n",
    "# 4.0 Making a Nice Figure with Flow Lines\n",
    "\n",
    "Now we can make a nice figure with some Flow/ Orientataion arrows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175e459-342d-4e0d-a2e3-2b53c84ecfa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peaks.axes_manager.navigation_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5200da6-f261-4563-8f04-7db1e10413c6",
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1)\n",
    "\n",
    "im = axs.imshow(peaks.isig[2].data,\n",
    "           cmap=cmap, interpolation='none', \n",
    "           extent=peaks.axes_manager.navigation_extent)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "fontprops = fm.FontProperties(size=24, weight=\"bold\")\n",
    "\n",
    "scalebar = AnchoredSizeBar(axs.transData,\n",
    "                           80, '80 nm', 'lower left', \n",
    "                           pad=0.1,\n",
    "                           color='black',\n",
    "                           frameon=False,\n",
    "                           size_vertical=7,\n",
    "                           fontproperties=fontprops)\n",
    "\n",
    "axs.add_artist(scalebar)\n",
    "axs.set_xticks([])\n",
    "axs.set_yticks([])\n",
    "cbar = fig.colorbar(im, ax=axs)\n",
    "cbar.set_ticks([0, np.pi/2, np.pi])\n",
    "cbar.set_ticklabels([\"0\", \"$\\pi/2$\", \"$\\pi$\"])\n",
    "cbar.set_label(\"Orientation\")\n",
    "vx = np.cos(peaks.isig[2].data)\n",
    "vy = np.sin(peaks.isig[2].data)\n",
    "\n",
    "nav_axes = peaks.axes_manager.navigation_axes\n",
    "sep =7\n",
    "axs.quiver(nav_axes[1].axis[::sep],nav_axes[0].axis[::sep], vx[::sep,::sep], vy[::sep, ::sep],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc021116-84a2-422b-992d-49a7e641f289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hyperspy-bundle] *",
   "language": "python",
   "name": "conda-env-hyperspy-bundle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
